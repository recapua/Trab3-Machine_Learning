{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração Numérica do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumário  \n",
    "Definição do Problema  \n",
    "        ---A Classificação  \n",
    "        ---Os atributos  \n",
    "Exploração Numérica  \n",
    "        ---Média, mediana e percentis  \n",
    "        ---Média, mediana e percentis por classe  \n",
    "        --- Gráficos  \n",
    "Árvore de Decisão  \n",
    "        ---Completa  \n",
    "        ---Reduzida  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe com 581012 exemplares e 12 atributos importado com sucesso\n"
     ]
    }
   ],
   "source": [
    "#importação da base de dados\n",
    "file = \"covtype.data\"\n",
    "\n",
    "#nome dos atributos\n",
    "#estamos descartando os atributos que descrevem o tipo do solo\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache', 'Cover_Type']\n",
    "\n",
    "#de 0 a 13 são os atributos listados acima, e 54 é a classificação\n",
    "usecols = list(range(0, 14)) + [54]\n",
    "\n",
    "#especifico o tipo de alguns parametros(os que não são simplesmente numéricos)\n",
    "dtype = {'Cover_Type': 'category', 'Wilderness_Area_Rawah' : bool, 'Wilderness_Area_Neota' : bool, 'Wilderness_Area_Comanche' : bool, 'Wilderness_Area_Cache' : bool}\n",
    "\n",
    "#lê o arquivo num pandas.dataframe\n",
    "dataset = pandas.read_csv(file, header = None, usecols = usecols, names = names, dtype = dtype)\n",
    "\n",
    "#adicionando uma coluna adicional para sintetizar os 4 boleanos que representam a Wilderness_area. \n",
    "#para uma única instância, somente um dos 4 booleanos pode ser verdadeiro, logo eles, em realidade, funcionam como uma categorização\n",
    "new_column = pandas.Series([1 if dataset['Wilderness_Area_Rawah'][i] else \n",
    "                            2 if dataset['Wilderness_Area_Neota'][i] else\n",
    "                            3 if dataset['Wilderness_Area_Comanche'][i] else\n",
    "                            4 for i in range(len(dataset.index)) ], dtype=\"category\")\n",
    "#elimina as colunas reduzidas\n",
    "dataset = dataset.drop(columns=['Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache'])\n",
    "#insere nova coluna na posição 10\n",
    "dataset.insert(loc = 10, column = 'Wilderness_Area', value = new_column)\n",
    "\n",
    "#atualiza names para refletir a mudança acima\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Cover_Type']\n",
    "\n",
    "print(\"Dataframe com %d exemplares e %d atributos importado com sucesso\" % (dataset.values.shape[0], dataset.values.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cover_Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cover_Type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ec710a3c0541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cover_Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cover_Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cover_Type'"
     ]
    }
   ],
   "source": [
    "#corr = dataset.corr()['Cover_Type'][dataset.corr()['Cover_Type'] < 1].abs()\n",
    "#corr.sort(ascending = False)\n",
    "#corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atributos importados e seus tipos de dados\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantidade de exemplares por classificação\n",
    "dataset.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um exemplar da base de dados, para visualização\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, geral\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, por classificação\n",
    "gp = dataset.groupby('Cover_Type')\n",
    "for name in names:\n",
    "    print(name)\n",
    "    display(gp[name].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma da altura, que se provou o mais importante atributo\n",
    "dataset['Elevation'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cover_Type'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz um scatter plot maneiro\n",
    "#para cada classificação, seleciona N amostras aleatórias pra serem plotadas\n",
    "seed = 7\n",
    "N = 250\n",
    "#markerTypes = {'1':'.', '2': 'x', '3': 'o', '4': '^', '5': '1', '6': '2', '7': '3'}\n",
    "markerTypes = {'1':'.', '2': '.', '3': '.', '4': '.', '5': '.', '6': '.', '7': '.'}\n",
    "points = []\n",
    "markers = []\n",
    "i = 0\n",
    "gp = dataset.groupby('Cover_Type', sort = False)\n",
    "samples = gp.apply(lambda x: x.sample(n = N, random_state = seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Slope'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Horizontal_Distance_To_Roadways'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Horizontal_Distance_To_Fire_Points'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Elevation'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz um scatter plot maneiro\n",
    "#só pega N amostras, sem pegar em igual numero de cada classificação\n",
    "seed = 7\n",
    "N = 250\n",
    "#markerTypes = {'1':'.', '2': 'x', '3': 'o', '4': '^', '5': '1', '6': '2', '7': '3'}\n",
    "markerTypes = {'1':'.', '2': '.', '3': '.', '4': '.', '5': '.', '6': '.', '7': '.'}\n",
    "points = []\n",
    "markers = []\n",
    "i = 0\n",
    "gp = dataset#.groupby('Cover_Type', sort = False)\n",
    "samples = gp.apply(lambda x: x.sample(n = 7*N, random_state = seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Horizontal_Distance_To_Roadways'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Horizontal_Distance_To_Fire_Points'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Elevation'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Horizontal_Distance_To_Fire_Points', 'Horizontal_Distance_To_Roadways'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Aspect', 'Slope'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico name1 x name2\n",
    "name1, name2 = 'Elevation', 'Wilderness_Area'\n",
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "for cover_type, group in samples.groupby('Cover_Type'):\n",
    "    \n",
    "    plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "    \n",
    "ax.set(xlabel=name1, ylabel=name2,\n",
    "       title=name1 + ' x ' + name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algumas funções auxiliares\n",
    "def print_feature_importances(dtc):\n",
    "    fi = dtc.feature_importances_\n",
    "    for i in range(len(fi)):\n",
    "        msg = \"%s: %f\" % (names[i], fi[i])\n",
    "        print(msg)\n",
    "       \n",
    "def print_decision_tree_info(estimator, verbose = False):\n",
    "    \n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    children_left = estimator.tree_.children_left\n",
    "    children_right = estimator.tree_.children_right\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    if(verbose): print(\"The binary tree structure has %s nodes and has \"\n",
    "          \"the following tree structure:\"\n",
    "          % n_nodes)\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            if(verbose): print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "        else:\n",
    "            if (verbose):print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "                  \"node %s.\"\n",
    "                  % (node_depth[i] * \"\\t\",\n",
    "                     i,\n",
    "                     children_left[i],\n",
    "                     feature[i],\n",
    "                     threshold[i],\n",
    "                     children_right[i],\n",
    "                     ))\n",
    "    print()\n",
    "    \n",
    "    print(\"Node count:\", n_nodes)\n",
    "    print(\"Leaf node count:\", sum(b for b in is_leaves))\n",
    "    print(\"Max node depth:\", node_depth.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:, 0:11]\n",
    "Y = array[:, 11]\n",
    "\n",
    "#preprocessa dataset\n",
    "#estava preprocessando, mas não fazia diferença\n",
    "#X_scale_temp = preprocessing.scale(X[:, 0:10])\n",
    "#X_scaled = np.append(X_scale_temp, X[:, 10].reshape(-1, 1), axis = 1)\n",
    "\n",
    "\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265681608908548"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentar descobrir o nivel de importancia dos atributos baseado na arvore de decisão\n",
    "dtc = DecisionTreeClassifier(random_state = seed)\n",
    "dtc.fit(X_train, Y_train)\n",
    "dtc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance diz a importÇancia relativa de cada atributo\n",
    "print_feature_importances(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_decision_tree_info(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#novamente árvore de decisão, porém reduzida a tres attributos\n",
    "X_3 = np.zeros((array.shape[0], 3))\n",
    "X_3[:, 0] = dataset['Elevation']\n",
    "X_3[:, 1] = dataset['Horizontal_Distance_To_Roadways']\n",
    "X_3[:, 2] = dataset['Horizontal_Distance_To_Fire_Points']\n",
    "Y = dataset.values[:, 11]\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train_3, X_validation_3, Y_train_3, Y_validation_3 = model_selection.train_test_split(X_3, Y, test_size = validation_size, random_state = seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_3 = DecisionTreeClassifier(random_state = seed)\n",
    "dtc_3.fit(X_train_3, Y_train_3)\n",
    "dtc_3.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importances(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_decision_tree_info(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limited decision tree\n",
    "dtc_lim = DecisionTreeClassifier(random_state = seed, max_depth = 20)\n",
    "dtc_lim.fit(X_train, Y_train)\n",
    "dtc_lim.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance diz a importÇancia relativa de cada atributo\n",
    "fi = dtc_lim.feature_importances_\n",
    "for i in range(len(fi)):\n",
    "    msg = \"%s: %f\" % (names[i], fi[i])\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = dtc_lim\n",
    "\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Node count:\", n_nodes)\n",
    "print(\"Leaf node count:\", sum(b for b in is_leaves))\n",
    "print(\"Max node depth:\", node_depth.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train_3, Y_train_3)\n",
    "knn.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
