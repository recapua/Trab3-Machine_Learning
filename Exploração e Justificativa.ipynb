{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração Numérica do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumário  \n",
    "Definição do Problema  \n",
    "        ---A Classificação  \n",
    "        ---Os atributos  \n",
    "Exploração Numérica  \n",
    "        ---Média, mediana e percentis  \n",
    "        ---Média, mediana e percentis por classe  \n",
    "        --- Gráficos  \n",
    "Árvore de Decisão  \n",
    "        ---Completa  \n",
    "        ---Reduzida  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "import sklearn as skl\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe com 581012 exemplares e 12 atributos importado com sucesso\n"
     ]
    }
   ],
   "source": [
    "#importação da base de dados\n",
    "file = \"covtype.data\"\n",
    "\n",
    "#nome dos atributos\n",
    "#estamos descartando os atributos que descrevem o tipo do solo\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache', 'Cover_Type']\n",
    "\n",
    "#de 0 a 13 são os atributos listados acima, e 54 é a classificação\n",
    "usecols = list(range(0, 14)) + [54]\n",
    "\n",
    "#especifico o tipo de alguns parametros(os que não são simplesmente numéricos)\n",
    "dtype = {'Cover_Type': 'category', 'Wilderness_Area_Rawah' : bool, 'Wilderness_Area_Neota' : bool, 'Wilderness_Area_Comanche' : bool, 'Wilderness_Area_Cache' : bool}\n",
    "\n",
    "#lê o arquivo num pandas.dataframe\n",
    "dataset = pandas.read_csv(file, header = None, usecols = usecols, names = names, dtype = dtype)\n",
    "\n",
    "#adicionando uma coluna adicional para sintetizar os 4 boleanos que representam a Wilderness_area. \n",
    "#para uma única instância, somente um dos 4 booleanos pode ser verdadeiro, logo eles, em realidade, funcionam como uma categorização\n",
    "new_column = pandas.Series([1 if dataset['Wilderness_Area_Rawah'][i] else \n",
    "                            2 if dataset['Wilderness_Area_Neota'][i] else\n",
    "                            3 if dataset['Wilderness_Area_Comanche'][i] else\n",
    "                            4 for i in range(len(dataset.index)) ], dtype=\"category\")\n",
    "#elimina as colunas reduzidas\n",
    "dataset = dataset.drop(columns=['Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache'])\n",
    "#insere nova coluna na posição 10\n",
    "dataset.insert(loc = 10, column = 'Wilderness_Area', value = new_column)\n",
    "\n",
    "#atualiza names para refletir a mudança acima\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Cover_Type']\n",
    "\n",
    "print(\"Dataframe com %d exemplares e %d atributos importado com sucesso\" % (dataset.values.shape[0], dataset.values.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = dataset.corr()['Cover_Type'][dataset.corr()['Cover_Type'] < 1].abs()\n",
    "#corr.sort(ascending = False)\n",
    "#corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atributos importados e seus tipos de dados\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantidade de exemplares por classificação\n",
    "dataset.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um exemplar da base de dados, para visualização\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, geral\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, por classificação\n",
    "gp = dataset.groupby('Cover_Type')\n",
    "for name in names:\n",
    "    print(name)\n",
    "    display(gp[name].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz um histograma do atributo:\n",
    "def histogram(att_name):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    dataset[att_name].hist()\n",
    "    ax.set(xlabel=att_name, ylabel = 'Number of Samples', title=att_name + ' Histogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram('Elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma da distância até foco de incêndio, que se provou um importante atributo\n",
    "histogram('Horizontal_Distance_To_Fire_Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma da distância até rodovias, que se provou um importante atributo\n",
    "histogram('Horizontal_Distance_To_Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma distribuição entre as categorias de cobertura\n",
    "histogram('Cover_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma distribuição do sombreamento ao meio dia, que não ajuda muito\n",
    "histogram('Hillshade_Noon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#faz um scatter plot maneiro\n",
    "seed = 7\n",
    "N = 250\n",
    "#markerTypes = {'1':'.', '2': 'x', '3': 'o', '4': '^', '5': '1', '6': '2', '7': '3'}\n",
    "markerTypes = {'1':'.', '2': '.', '3': '.', '4': '.', '5': '.', '6': '.', '7': '.'}\n",
    "points = []\n",
    "markers = []\n",
    "gp = dataset.groupby('Cover_Type', sort = False)\n",
    "samples_stratified = gp.apply(lambda x: x.sample(n = N, random_state = seed))\n",
    "#para cada classificação, seleciona N amostras aleatórias pra serem plotadas\n",
    "\n",
    "gp_random = dataset\n",
    "samples_random = gp_random.apply(lambda x: x.sample(n = 7*N, random_state = seed))\n",
    "\n",
    "#plota grafico name1 x name2\n",
    "def scatter_plot(name1, name2, stratified = True):\n",
    "    title_name = name1 + ' x ' + name2 + (' (E)' if stratified else ' (A)')\n",
    "    samples = samples_stratified if stratified else samples_random\n",
    "    fig, ax = plt.subplots()\n",
    "    for cover_type, group in samples.groupby('Cover_Type'):\n",
    "\n",
    "        plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "\n",
    "    ax.set(xlabel=name1, ylabel=name2,\n",
    "           title=title_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Slope', stratified = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Slope', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Roadways', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Roadways', stratified = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Fire_Points', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Fire_Points', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Elevation', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Elevation', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Hillshade_9am', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Hillshade_9am', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Slope', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Slope', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Aspect', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Aspect', stratified = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algumas funções auxiliares\n",
    "def print_feature_importances(dtc):\n",
    "    fi = dtc.feature_importances_\n",
    "    for i in range(len(fi)):\n",
    "        msg = \"%s: %f\" % (names[i], fi[i])\n",
    "        print(msg)\n",
    "       \n",
    "def print_decision_tree_info(estimator, verbose = False):\n",
    "    \n",
    "    print(type(estimator))\n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    children_left = estimator.tree_.children_left\n",
    "    children_right = estimator.tree_.children_right\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    if(verbose): print(\"The binary tree structure has %s nodes and has \"\n",
    "          \"the following tree structure:\"\n",
    "          % n_nodes)\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            if(verbose): print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "        else:\n",
    "            if (verbose):print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "                  \"node %s.\"\n",
    "                  % (node_depth[i] * \"\\t\",\n",
    "                     i,\n",
    "                     children_left[i],\n",
    "                     feature[i],\n",
    "                     threshold[i],\n",
    "                     children_right[i],\n",
    "                     ))\n",
    "    print()\n",
    "    \n",
    "    print(\"Node count:\", n_nodes)\n",
    "    print(\"Leaf node count:\", sum(b for b in is_leaves))\n",
    "    print(\"Max node depth:\", node_depth.max())\n",
    "    \n",
    "def get_decision_tree_info(estimator, verbose = False):\n",
    "    \n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    children_left = estimator.tree_.children_left\n",
    "    children_right = estimator.tree_.children_right\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    if(verbose): print(\"The binary tree structure has %s nodes and has \"\n",
    "          \"the following tree structure:\"\n",
    "          % n_nodes)\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            if(verbose): print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "        else:\n",
    "            if (verbose):print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "                  \"node %s.\"\n",
    "                  % (node_depth[i] * \"\\t\",\n",
    "                     i,\n",
    "                     children_left[i],\n",
    "                     feature[i],\n",
    "                     threshold[i],\n",
    "                     children_right[i],\n",
    "                     ))\n",
    "    print()\n",
    "    \n",
    "    return (n_nodes, sum(b for b in is_leaves), node_depth.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:, 0:11]\n",
    "Y = array[:, 11]\n",
    "\n",
    "#preprocessa dataset\n",
    "#estava preprocessando, mas não fazia diferença\n",
    "#X_scale_temp = preprocessing.scale(X[:, 0:10])\n",
    "#X_scaled = np.append(X_scale_temp, X[:, 10].reshape(-1, 1), axis = 1)\n",
    "\n",
    "\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "seed = 7\n",
    "def EstimarAcuraciaMetodo(metodo, k = 10):\n",
    "    kfold = model_selection.KFold(n_splits = k, shuffle = True, random_state = 121)#, random_state = seed)\n",
    "    cv_results = model_selection.cross_validate(metodo, X_train, Y_train, cv = kfold, scoring = scoring)\n",
    "    print(cv_results)\n",
    "    msg = \"%s média entre os %d folds: %f, com desvio padrão de %f ,em \" % (scoring, k, cv_results['test_score'].mean(), cv_results['test_score'].std())\n",
    "    print(msg)\n",
    "    msg2 = \"tempo médio de treino: %f, para %d samples por fit\" % (cv_results['fit_time'].mean(), (len(X_train) // k) * (k-1))\n",
    "    print(msg2)\n",
    "\n",
    "def EstimarAcuraciaMetodo_dtc(metodo, k = 10):\n",
    "    kfold = model_selection.KFold(n_splits = k, shuffle = True, random_state = 121)#, random_state = seed)\n",
    "    cv_results = model_selection.cross_validate(metodo, X_train, Y_train, cv = kfold, scoring = scoring, return_estimator=True)\n",
    "    #print(cv_results)\n",
    "    msg = \"%s média entre os %d folds: %f, com desvio padrão de %f ,em \" % (scoring, k, cv_results['test_score'].mean(), cv_results['test_score'].std())\n",
    "    print(msg)\n",
    "    msg2 = \"tempo médio de treino: %f, para %d samples por fit\" % (cv_results['fit_time'].mean(), (len(X_train) // k) * (k-1))\n",
    "    print(msg2)\n",
    "    nodes_n = []\n",
    "    for dtc in cv_results['estimator']:\n",
    "        nodes_n.append(get_decision_tree_info(dtc)[0])\n",
    "    print(\"Média de %f nós por árvore gerada\" % mean(nodes_n))\n",
    "    print(nodes_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265681608908548"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentar descobrir o nivel de importancia dos atributos baseado na arvore de decisão\n",
    "dtc = DecisionTreeClassifier(random_state = seed)\n",
    "dtc.fit(X_train, Y_train)\n",
    "dtc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation: 0.346055\n",
      "Aspect: 0.031844\n",
      "Slope: 0.022997\n",
      "Horizontal_Distance_To_Hydrology: 0.070997\n",
      "Vertical_Distance_To_Hydrology: 0.056597\n",
      "Horizontal_Distance_To_Roadways: 0.164803\n",
      "Hillshade_9am: 0.034835\n",
      "Hillshade_Noon: 0.039353\n",
      "Hillshade_3pm: 0.027806\n",
      "Horizontal_Distance_To_Fire_Points: 0.165863\n",
      "Wilderness_Area: 0.038850\n"
     ]
    }
   ],
   "source": [
    "#feature importance diz a importância relativa de cada atributo\n",
    "print_feature_importances(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Node count: 56881\n",
      "Leaf node count: 28441\n",
      "Max node depth: 41\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_info(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy média entre os 10 folds: 0.922661, com desvio padrão de 0.001399 ,em \n",
      "tempo médio de treino: 6.071490, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 52896.000000 nós por árvore gerada\n",
      "[52857, 53283, 53079, 53393, 52847, 52277, 52979, 52787, 52531, 52927]\n"
     ]
    }
   ],
   "source": [
    "dtcN = DecisionTreeClassifier(random_state = seed)\n",
    "EstimarAcuraciaMetodo_dtc(dtcN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arvore de decisão limitada a profundidade de 1\n",
      "accuracy média entre os 10 folds: 0.633617, com desvio padrão de 0.001610 ,em \n",
      "tempo médio de treino: 1.220608, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 3.000000 nós por árvore gerada\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      " \n",
      "Arvore de decisão limitada a profundidade de 3\n",
      "accuracy média entre os 10 folds: 0.674546, com desvio padrão de 0.001216 ,em \n",
      "tempo médio de treino: 1.814702, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 15.000000 nós por árvore gerada\n",
      "[15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
      " \n",
      "Arvore de decisão limitada a profundidade de 5\n",
      "accuracy média entre os 10 folds: 0.692441, com desvio padrão de 0.001836 ,em \n",
      "tempo médio de treino: 2.392118, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 63.000000 nós por árvore gerada\n",
      "[63, 63, 63, 63, 63, 63, 63, 63, 63, 63]\n",
      " \n",
      "Arvore de decisão limitada a profundidade de 10\n",
      "accuracy média entre os 10 folds: 0.763163, com desvio padrão de 0.001660 ,em \n",
      "tempo médio de treino: 3.726967, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 1534.800000 nós por árvore gerada\n",
      "[1555, 1545, 1539, 1555, 1539, 1541, 1531, 1491, 1505, 1547]\n",
      " \n",
      "Arvore de decisão limitada a profundidade de 20\n",
      "accuracy média entre os 10 folds: 0.904847, com desvio padrão de 0.001855 ,em \n",
      "tempo médio de treino: 5.769586, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 34653.000000 nós por árvore gerada\n",
      "[34355, 35617, 35293, 34559, 33835, 34703, 34527, 34845, 34477, 34319]\n",
      " \n",
      "Arvore de decisão limitada a profundidade de 30\n",
      "accuracy média entre os 10 folds: 0.922523, com desvio padrão de 0.001256 ,em \n",
      "tempo médio de treino: 6.097641, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 52640.000000 nós por árvore gerada\n",
      "[52549, 53025, 52841, 53073, 52657, 52113, 52781, 52389, 52319, 52653]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#experimetando com profundidades máximas. Já fiz a sem limite de profundidade aqui em cima\n",
    "n_list = [1, 3, 5, 10,20, 30]\n",
    "for i in n_list:\n",
    "    print(\"Arvore de decisão limitada a profundidade de %d\" % i)\n",
    "    dtc1 = DecisionTreeClassifier(random_state = seed, max_depth = i)\n",
    "    EstimarAcuraciaMetodo_dtc(dtc1)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#novamente árvore de decisão, porém reduzida a tres attributos\n",
    "X_3 = np.zeros((array.shape[0], 3))\n",
    "X_3[:, 0] = dataset['Elevation']\n",
    "X_3[:, 1] = dataset['Horizontal_Distance_To_Roadways']\n",
    "X_3[:, 2] = dataset['Horizontal_Distance_To_Fire_Points']\n",
    "Y = dataset.values[:, 11]\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train_3, X_validation_3, Y_train_3, Y_validation_3 = model_selection.train_test_split(X_3, Y, test_size = validation_size, random_state = seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimarAcuraciaMetodo_dtc_3(metodo, k = 10):\n",
    "    kfold = model_selection.KFold(n_splits = k, shuffle = True, random_state = 121)#, random_state = seed)\n",
    "    cv_results = model_selection.cross_validate(metodo, X_train_3, Y_train_3, cv = kfold, scoring = scoring, return_estimator=True)\n",
    "    #print(cv_results)\n",
    "    msg = \"%s média entre os %d folds: %f, com desvio padrão de %f ,em \" % (scoring, k, cv_results['test_score'].mean(), cv_results['test_score'].std())\n",
    "    print(msg)\n",
    "    msg2 = \"tempo médio de treino: %f, para %d samples por fit\" % (cv_results['fit_time'].mean(), (len(X_train_3) // k) * (k-1))\n",
    "    print(msg2)\n",
    "    nodes_n = []\n",
    "    for dtc in cv_results['estimator']:\n",
    "        nodes_n.append(get_decision_tree_info(dtc)[0])\n",
    "    print(\"Média de %f nós por árvore gerada\" % mean(nodes_n))\n",
    "    print(nodes_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172766623925372"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_3 = DecisionTreeClassifier(random_state = seed)\n",
    "dtc_3.fit(X_train_3, Y_train_3)\n",
    "dtc_3.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation: 0.432133\n",
      "Aspect: 0.276885\n",
      "Slope: 0.290982\n"
     ]
    }
   ],
   "source": [
    "print_feature_importances(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Node count: 136457\n",
      "Leaf node count: 68229\n",
      "Max node depth: 47\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_info(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy média entre os 10 folds: 0.815591, com desvio padrão de 0.001762 ,em \n",
      "tempo médio de treino: 2.616317, para 418320 samples por fit\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Média de 124847.200000 nós por árvore gerada\n",
      "[124833, 125285, 124607, 124595, 124583, 124985, 124883, 124831, 125111, 124759]\n"
     ]
    }
   ],
   "source": [
    "dtc_3_N = DecisionTreeClassifier(random_state = seed)\n",
    "EstimarAcuraciaMetodo_dtc_3(dtc_3_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train_3, Y_train_3)\n",
    "knn.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
