{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração Numérica do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumário  \n",
    "Definição do Problema  \n",
    "        ---A Classificação  \n",
    "        ---Os atributos  \n",
    "Exploração Numérica  \n",
    "        ---Média, mediana e percentis  \n",
    "        ---Média, mediana e percentis por classe  \n",
    "        --- Gráficos  \n",
    "Árvore de Decisão  \n",
    "        ---Completa  \n",
    "        ---Reduzida  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "import sklearn as skl\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe com 581012 exemplares e 12 atributos importado com sucesso\n"
     ]
    }
   ],
   "source": [
    "#importação da base de dados\n",
    "file = \"covtype.data\"\n",
    "\n",
    "#nome dos atributos\n",
    "#estamos descartando os atributos que descrevem o tipo do solo\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache', 'Cover_Type']\n",
    "\n",
    "#de 0 a 13 são os atributos listados acima, e 54 é a classificação\n",
    "usecols = list(range(0, 14)) + [54]\n",
    "\n",
    "#especifico o tipo de alguns parametros(os que não são simplesmente numéricos)\n",
    "dtype = {'Cover_Type': 'category', 'Wilderness_Area_Rawah' : bool, 'Wilderness_Area_Neota' : bool, 'Wilderness_Area_Comanche' : bool, 'Wilderness_Area_Cache' : bool}\n",
    "\n",
    "#lê o arquivo num pandas.dataframe\n",
    "dataset = pandas.read_csv(file, header = None, usecols = usecols, names = names, dtype = dtype)\n",
    "\n",
    "#adicionando uma coluna adicional para sintetizar os 4 boleanos que representam a Wilderness_area. \n",
    "#para uma única instância, somente um dos 4 booleanos pode ser verdadeiro, logo eles, em realidade, funcionam como uma categorização\n",
    "new_column = pandas.Series([1 if dataset['Wilderness_Area_Rawah'][i] else \n",
    "                            2 if dataset['Wilderness_Area_Neota'][i] else\n",
    "                            3 if dataset['Wilderness_Area_Comanche'][i] else\n",
    "                            4 for i in range(len(dataset.index)) ], dtype=\"category\")\n",
    "#elimina as colunas reduzidas\n",
    "dataset = dataset.drop(columns=['Wilderness_Area_Rawah', 'Wilderness_Area_Neota', 'Wilderness_Area_Comanche', 'Wilderness_Area_Cache'])\n",
    "#insere nova coluna na posição 10\n",
    "dataset.insert(loc = 10, column = 'Wilderness_Area', value = new_column)\n",
    "\n",
    "#atualiza names para refletir a mudança acima\n",
    "names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Cover_Type']\n",
    "\n",
    "print(\"Dataframe com %d exemplares e %d atributos importado com sucesso\" % (dataset.values.shape[0], dataset.values.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = dataset.corr()['Cover_Type'][dataset.corr()['Cover_Type'] < 1].abs()\n",
    "#corr.sort(ascending = False)\n",
    "#corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atributos importados e seus tipos de dados\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantidade de exemplares por classificação\n",
    "dataset.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um exemplar da base de dados, para visualização\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, geral\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumário dos dados, por classificação\n",
    "gp = dataset.groupby('Cover_Type')\n",
    "for name in names:\n",
    "    print(name)\n",
    "    display(gp[name].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz um histograma do atributo:\n",
    "def histogram(att_name):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    dataset[att_name].hist()\n",
    "    ax.set(xlabel=att_name, ylabel = 'Number of Samples', title=att_name + ' Histogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram('Elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma da distância até foco de incêndio, que se provou um importante atributo\n",
    "histogram('Horizontal_Distance_To_Fire_Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma da distância até rodovias, que se provou um importante atributo\n",
    "histogram('Horizontal_Distance_To_Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma distribuição entre as categorias de cobertura\n",
    "histogram('Cover_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um histograma distribuição do sombreamento ao meio dia, que não ajuda muito\n",
    "histogram('Hillshade_Noon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#faz um scatter plot maneiro\n",
    "seed = 7\n",
    "N = 250\n",
    "#markerTypes = {'1':'.', '2': 'x', '3': 'o', '4': '^', '5': '1', '6': '2', '7': '3'}\n",
    "markerTypes = {'1':'.', '2': '.', '3': '.', '4': '.', '5': '.', '6': '.', '7': '.'}\n",
    "points = []\n",
    "markers = []\n",
    "gp = dataset.groupby('Cover_Type', sort = False)\n",
    "samples_stratified = gp.apply(lambda x: x.sample(n = N, random_state = seed))\n",
    "#para cada classificação, seleciona N amostras aleatórias pra serem plotadas\n",
    "\n",
    "gp_random = dataset\n",
    "samples_random = gp_random.apply(lambda x: x.sample(n = 7*N, random_state = seed))\n",
    "\n",
    "#plota grafico name1 x name2\n",
    "def scatter_plot(name1, name2, stratified = True):\n",
    "    title_name = name1 + ' x ' + name2 + (' (E)' if stratified else ' (A)')\n",
    "    samples = samples_stratified if stratified else samples_random\n",
    "    fig, ax = plt.subplots()\n",
    "    for cover_type, group in samples.groupby('Cover_Type'):\n",
    "\n",
    "        plt.scatter(group[name1], group[name2], marker = markerTypes[cover_type])\n",
    "\n",
    "    ax.set(xlabel=name1, ylabel=name2,\n",
    "           title=title_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Slope', stratified = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Slope', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Roadways', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Roadways', stratified = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Fire_Points', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Horizontal_Distance_To_Fire_Points', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Elevation', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Elevation', 'Elevation', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Hillshade_9am', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Hillshade_9am', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Slope', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Slope', stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_Noon', 'Aspect', stratified = True)\n",
    "\n",
    "#plota grafico Elevation x Slope\n",
    "scatter_plot('Hillshade_3pm', 'Aspect', stratified = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algumas funções auxiliares\n",
    "def print_feature_importances(dtc):\n",
    "    fi = dtc.feature_importances_\n",
    "    for i in range(len(fi)):\n",
    "        msg = \"%s: %f\" % (names[i], fi[i])\n",
    "        print(msg)\n",
    "       \n",
    "def print_decision_tree_info(estimator, verbose = False):\n",
    "    \n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    children_left = estimator.tree_.children_left\n",
    "    children_right = estimator.tree_.children_right\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    if(verbose): print(\"The binary tree structure has %s nodes and has \"\n",
    "          \"the following tree structure:\"\n",
    "          % n_nodes)\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            if(verbose): print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "        else:\n",
    "            if (verbose):print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "                  \"node %s.\"\n",
    "                  % (node_depth[i] * \"\\t\",\n",
    "                     i,\n",
    "                     children_left[i],\n",
    "                     feature[i],\n",
    "                     threshold[i],\n",
    "                     children_right[i],\n",
    "                     ))\n",
    "    print()\n",
    "    \n",
    "    print(\"Node count:\", n_nodes)\n",
    "    print(\"Leaf node count:\", sum(b for b in is_leaves))\n",
    "    print(\"Max node depth:\", node_depth.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:, 0:11]\n",
    "Y = array[:, 11]\n",
    "\n",
    "#preprocessa dataset\n",
    "#estava preprocessando, mas não fazia diferença\n",
    "#X_scale_temp = preprocessing.scale(X[:, 0:10])\n",
    "#X_scaled = np.append(X_scale_temp, X[:, 10].reshape(-1, 1), axis = 1)\n",
    "\n",
    "\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "seed = 7\n",
    "def EstimarAcuraciaMetodo(metodo, k = 10):\n",
    "    kfold = model_selection.KFold(n_splits = k, shuffle = True, random_state = 121)#, random_state = seed)\n",
    "    cv_results = model_selection.cross_validate(metodo, X, Y, cv = kfold, scoring = scoring)\n",
    "    print(cv_results)\n",
    "    msg = \"%s média entre os %d folds: %f, com desvio padrão de %f ,em \" % (scoring, k, cv_results['test_score'].mean(), cv_results['test_score'].std())\n",
    "    print(msg)\n",
    "    msg2 = \"tempo médio de treino: %f, para %d samples por fit\" % (cv_results['fit_time'].mean(), (len(X_train) // k) * (k-1))\n",
    "    print(msg2)\n",
    "\n",
    "def EstimarAcuraciaMetodo_dtc(metodo, k = 10):\n",
    "    kfold = model_selection.KFold(n_splits = k, shuffle = True, random_state = 121)#, random_state = seed)\n",
    "    cv_results = model_selection.cross_validate(metodo, X, Y, cv = kfold, scoring = scoring, return_estimator=True)\n",
    "    print(cv_results)\n",
    "    msg = \"%s média entre os %d folds: %f, com desvio padrão de %f ,em \" % (scoring, k, cv_results['test_score'].mean(), cv_results['test_score'].std())\n",
    "    print(msg)\n",
    "    msg2 = \"tempo médio de treino: %f, para %d samples por fit\" % (cv_results['fit_time'].mean(), (len(X_train) // k) * (k-1))\n",
    "    print(msg2)\n",
    "    print(\"Média de %d nós na arvore\" % cv_results['estimator'].tree_.node_count.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265681608908548"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentar descobrir o nivel de importancia dos atributos baseado na arvore de decisão\n",
    "dtc = DecisionTreeClassifier(random_state = seed)\n",
    "dtc.fit(X_train, Y_train)\n",
    "dtc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation: 0.346055\n",
      "Aspect: 0.031844\n",
      "Slope: 0.022997\n",
      "Horizontal_Distance_To_Hydrology: 0.070997\n",
      "Vertical_Distance_To_Hydrology: 0.056597\n",
      "Horizontal_Distance_To_Roadways: 0.164803\n",
      "Hillshade_9am: 0.034835\n",
      "Hillshade_Noon: 0.039353\n",
      "Hillshade_3pm: 0.027806\n",
      "Horizontal_Distance_To_Fire_Points: 0.165863\n",
      "Wilderness_Area: 0.038850\n"
     ]
    }
   ],
   "source": [
    "#feature importance diz a importância relativa de cada atributo\n",
    "print_feature_importances(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node count: 56881\n",
      "Leaf node count: 28441\n",
      "Max node depth: 41\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_info(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_validate() got an unexpected keyword argument 'return_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7314a9d31226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdtcN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mEstimarAcuraciaMetodo_dtc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtcN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-acb8505441d9>\u001b[0m in \u001b[0;36mEstimarAcuraciaMetodo_dtc\u001b[1;34m(metodo, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mEstimarAcuraciaMetodo_dtc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetodo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, random_state = seed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetodo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s média entre os %d folds: %f, com desvio padrão de %f ,em \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_validate() got an unexpected keyword argument 'return_estimator'"
     ]
    }
   ],
   "source": [
    "print(skl.__version__)\n",
    "dtcN = DecisionTreeClassifier(random_state = seed)\n",
    "EstimarAcuraciaMetodo_dtc(dtcN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arvore de decisão limitada a profundidade de 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_validate() got an unexpected keyword argument 'return_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5cab33394bfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Arvore de decisão limitada a profundidade de %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdtc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mEstimarAcuraciaMetodo_dtc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-acb8505441d9>\u001b[0m in \u001b[0;36mEstimarAcuraciaMetodo_dtc\u001b[1;34m(metodo, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mEstimarAcuraciaMetodo_dtc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetodo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, random_state = seed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetodo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s média entre os %d folds: %f, com desvio padrão de %f ,em \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_validate() got an unexpected keyword argument 'return_estimator'"
     ]
    }
   ],
   "source": [
    "#experimetando com profundidades máximas. Já fiz a sem limite de profundidade aqui em cima\n",
    "n_list = [1, 3, 5, 10,20, 30]\n",
    "for i in n_list:\n",
    "    print(\"Arvore de decisão limitada a profundidade de %d\" % i)\n",
    "    dtc1 = DecisionTreeClassifier(random_state = seed, max_depth = i)\n",
    "    EstimarAcuraciaMetodo_dtc(dtc1)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brincando com pesos\n",
    "#weights ={'Elevation': 1, 'Aspect':1, 'Slope':1, 'Horizontal_Distance_To_Hydrology':1, 'Vertical_Distance_To_Hydrology':1, 'Horizontal_Distance_To_Roadways':1, 'Hillshade_9am':1, 'Hillshade_Noon':1, 'Hillshade_3pm':1, 'Horizontal_Distance_To_Fire_Points':1, 'Wilderness_Area_Rawah':1, 'Wilderness_Area_Neota':1, 'Wilderness_Area_Comanche':1, 'Wilderness_Area_Cache':1, 'Cover_Type'}\n",
    "weights ={'1': 1, '2':1, '3':1, '4':1, '5':1, '6':1, '7':1}\n",
    "dtc_w = DecisionTreeClassifier(random_state = seed, class_weight = weights)\n",
    "dtc_w.fit(X_train, Y_train)\n",
    "print(dtc_w.score(X_validation, Y_validation))\n",
    "print_feature_importances(dtc_w)\n",
    "print_decision_tree_info(dtc_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#novamente árvore de decisão, porém reduzida a tres attributos\n",
    "X_3 = np.zeros((array.shape[0], 3))\n",
    "X_3[:, 0] = dataset['Elevation']\n",
    "X_3[:, 1] = dataset['Horizontal_Distance_To_Roadways']\n",
    "X_3[:, 2] = dataset['Horizontal_Distance_To_Fire_Points']\n",
    "Y = dataset.values[:, 11]\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train_3, X_validation_3, Y_train_3, Y_validation_3 = model_selection.train_test_split(X_3, Y, test_size = validation_size, random_state = seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_3 = DecisionTreeClassifier(random_state = seed)\n",
    "dtc_3.fit(X_train_3, Y_train_3)\n",
    "dtc_3.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importances(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_decision_tree_info(dtc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limited decision tree\n",
    "dtc_lim = DecisionTreeClassifier(random_state = seed, max_depth = 20)\n",
    "dtc_lim.fit(X_train, Y_train)\n",
    "dtc_lim.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance diz a importÇancia relativa de cada atributo\n",
    "fi = dtc_lim.feature_importances_\n",
    "for i in range(len(fi)):\n",
    "    msg = \"%s: %f\" % (names[i], fi[i])\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = dtc_lim\n",
    "\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Node count:\", n_nodes)\n",
    "print(\"Leaf node count:\", sum(b for b in is_leaves))\n",
    "print(\"Max node depth:\", node_depth.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train_3, Y_train_3)\n",
    "knn.score(X_validation_3, Y_validation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
